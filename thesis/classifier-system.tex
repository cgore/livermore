\input{parameters}

\subsection{Trivially Modified Algorithms}
There are several algorithms from XCS and XCSR that are only slightly modified for our purposes from their original forms.

\begin{description}

\item[The \emph{Generate Match Set} Algorithm.]
This is the \emph{GENERATE MATCH SET} function in \cite{ButzWilson}.
The match set $M$ contains all of the classifiers in the population $P$ which match the current situation.  After filling the match set with all pre-existing matching classifiers, it repeatedly generates new covering classifiers until the minimum number of actions is satisfied.

\item[The \emph{Select Action} Algorithm.]
This is the same as in traditional XCS.
There are two methods for selecting an action used here: either randomly, or the best action.

\item[The \emph{Generate Action Set} Algorithm.]
This is the \emph{GENERATE ACTION SET} function in \cite{ButzWilson}.
It forms the action set $A$ out of the match set $M$, all of the classifiers that match the selected action.

\item[The \emph{Update Set} Algorithm.]
This is the \emph{UPDATE SET} function in \cite{ButzWilson}.
It updates the parameters for classifiers in the action set.

\item[The \emph{Update Fitness} Algorithm.]
\label{sec:update-fitness}
This is the \emph{UPDATE FITNESS} function in \cite{ButzWilson}.
The fitness of all of the classifiers in the action set are updated in a normalized manner.

\item[The \emph{Run GA} Algorithm.]
This is the \emph{RUN GA} function in \cite{ButzWilson}.
It runs a simple genetic algorithm, not on the full population $P$, but instead only on the action set $A$, in order to induce niching.

\item [The \emph{Select Offspring} Algorithm.]
This is the \emph{SELECT OFFSPRING} function in \cite{ButzWilson}.
It uses a roulette-wheel method of selection.

\item [The \emph{Insert into the Population} Algorithm.]
\index{insert into the population algorithm@\emph{insert into the population} algorithm}
This is the \emph{INSERT IN POPULATION} algorithm in \cite{ButzWilson}.
It is slightly more complex than just pushing the new classifier into the population list:
we need to check to see if it is already present in the population.
If it is, we must increment that classifier's numerosity instead.
For a new classifier $r$, find an $r' \in P$,
\index{population}
with $P$ being the entire population,
such that $r$ and $r'$ are identical.
If such an $r'$ exists, increment $r'_n$;
otherwise insert $r$ into $P$.

\item [The \emph{Delete from Population} Algorithm.]
This is the same as the \emph{DELETE FROM POPULATION} function in \cite{ButzWilson}.
It decides which members of the population are suitable for deletion, allowing for niching, and then removes low-fitness individuals.

\item [The \emph{Deletion Vote} Algorithm.]
\label{sec:deletion-vote}
\index{deletion vote algorithm@\emph{deletion vote} algorithm}
This is the same as the \emph{DELETION VOTE} algorithm in \cite{ButzWilson}.
The deletion vote for a classifier $r$ is dependent upon its action set size estimate.
\index{action set size estimate}
Let $F_{average}$ be the average fitness in the entire population.
We want classifiers with sufficient experience and a significantly lower than average fitness than the rest of the population to be deleted before others.
Expressed in terms of the TSC parameters as outlined in \S\ref{sec:parameters}:
\begin{equation}
r_{exp} > \theta_{del} \bigwedge \frac{r_F}{r_n} < \delta F_{average}.
\end{equation}
\index{experience}
\index{deletion threshold}
\index{GA fitness}
\index{numerosity}
This then returns
\begin{equation}
\frac{r_{as} r_n F_{average}}
   {\left( \frac{r_F}
               {r_n} \right)}
= 
\frac{r_{as} r_n^2 F_{average}}
   {r_F}
\end{equation}
\index{action set size estimate}
as the deletion vote for this classifier $r$;
otherwise it returns
$r_{as} r_n$
as the deletion vote for this classifier $r$.

\item [The \emph{Do Action Set Subsumption} Algorithm.]
This is the \emph{DO ACTION SET SUBSUMPTION} function in \cite{ButzWilson}.
The function chooses the subsumer from the most general classifiers capable of subsumption and then subsumes all possible classifiers in to the subsumer.

\item [The \emph{Could Subsume?} Predicate.]
\label{sec:could-subsume?}
We say that a specific classifier $r$ is capable of subsuming others if it has both sufficient accuracy and sufficient experience.
That is, if the experience of the classifier is greater than the
minimal subsumption experience threshold\index{minimal subsumption experience},
and the prediction error of the classifier is less than the equal error threshold.
In symbols:
\begin{equation}
r_{exp} > \theta_{sub} \bigwedge r_{\epsilon} < \epsilon_0.
\end{equation}

\item [The \emph{Subsume?} Predicate.]
This is called \emph{DOES SUBSUME} in \cite{ButzWilson}.
A classifier $r^1$ subsumes another classifier $r^2$ if the following conditions are all met:
\begin{algorithmic}[1]
\STATE Their actions are identical: $r^1_a = r^2_a$.
\STATE The classifier $r^1$ is capable of subsumption, as decided by the \emph{could subsume?} predicate described in \S\ref{sec:could-subsume?}.
\STATE The classifier $r^1$ is more general than the classifier $r^2$, as decided by the \emph{more general?} predicate described in \S\ref{sec:more-general?}.
\end{algorithmic}

\end{description}

\subsection{The \emph{Match?} Predicate}
\label{sec:match?}
\index{match? predicate@\emph{match?} predicate}
This is based upon the algorithm called \emph{DOES MATCH} in \cite{ButzWilson}, but it has been generalized in order to suit our needs here.
Assume a classifier $r$ and a situation $\sigma$.
In traditional learning classifiers, $\sigma \in \{false, true\}$ which is usually represented $\{0,1\}$,
and therefore it is only necessary to see if every element in the condition part of the classifier $r$,  that is $r_c$, is either equal to each other or a covering symbol in $r$:
\begin{equation}
   \left( r_{c_i} = \sigma_i \bigvee r_{c_i} = \# \right)
      \forall i \in \mathbb{Z}_{|r_c| = |\sigma|}.
\end{equation}
For us, it is slightly more involved due to the more complex nature of the conditions used in the construction of the classifiers.

\begin{description}

\item [The \emph{match?} predicate for ternary values.]
For ternary values as used in traditional learning classifiers, a ternary predicate $t$ matches a situation element $x$ when either
$t = x$ or $t = \#$, the covering symbol.
Similarly, a ternary predicate $t$ matches a second ternary predicate $u$ when $t$ matches all of the situations matched by $u$;
that is, when $t = u \bigvee t = \#$.

\item [The \emph{match?} predicate for ranges.]
For ranges as used in Wilson's XCSR \cite{WilsonXCSR}, a range predicate $r$ matches a situation $x$ when that situation $x$ lies within the lower and upper bounds specified by the range predicate, $l \le x \le u$.

\item [The \emph{match?} predicate for a time-series.]
If we take the data along the straight line segment from the initial point $A$ to the final point $B$, forming a vector $d$, we can then form $d'$ by applying $\phi$ to each element in $d$:
\begin{equation}
d'_i = \phi \left(d_i\right) \forall d_i \in d.
\end{equation}
The predicate is said to match the data if and only if
\begin{equation}
l \le \omega \left( d' \right) \le u.
\end{equation}
When all of the predicates of the rule match, then the rule matches; the rule then recommends a particular classification or action.

Two situations $\sigma_1$ and $\sigma_2$ match if every one of their elements match element-wise:
\begin{equation}
   \mathrm{match?}\left( \sigma_{1_i}, \sigma_{2_i} \right) = true \;
      \forall i \in \mathbb{Z}_{|\sigma_1| = |\sigma_2|}.
\end{equation}

\item [The \emph{match?} predicate for classifiers and situations.]
A classifier $r$ matches a situation $\sigma$
if $r^1$ and $r^2$ match,
as decided by the \emph{match?} predicate described in \S\ref{sec:match?},
and at least one of the elements of the classifier is more general in $r^1$ than in $r^2$.

\item [The \emph{match?} predicate for classifiers.]
A classifier $r^1$ matches another classifier $r^2$
if the environment condition of $r^1$ matches the environment condition of the classifier $r^2$.

\end{description}

\subsection{The \emph{Generate Covering Classifier} Algorithm}
This is derived from the \emph{GENERATE COVERING CLASSIFIER} function in \cite{ButzWilson}.
It creates a classifier which matches the current situation.
This is handled somewhat differently in TSC than in XCS or in XCSR, and the method operates as described in Algorithm~\ref{alg:generating-covering-classifiers}.
\begin{algorithm}
\caption{Generating covering classifiers.}
\begin{algorithmic}[1]
\label{alg:generating-covering-classifiers}
\INPUT a TSC instance.
\LET $l$ be randomly chosen, $1 \le l \le $ the maximum environment condition length.
\LETARROW{$c$, the condition} $nil = \{\}$, an empty list.
\LETARROW{$a$, the action} a random element from the set of all possible actions that are not in the match set.
\FOR{$l$ times}
  \PUSH{a covering predicate}{$c$}
\ENDFOR
\RETURN a new classifier instance with environment condition $c$, action $a$, time stamp set to the current number of situations, and the rest of the slots set to their defaults. 
\end{algorithmic}
\end{algorithm}

%\subsection{The \emph{Crossover} Algorithm}
%This serves the same purpose as \emph{APPLY CROSSOVER} in \cite{ButzWilson}.
%The method of crossover used is described in \S\ref{sec:crossover} here.

%\subsection{The \emph{Mutate} Algorithm}
%\index{mutate algorithm@\emph{mutate} algorithm}
%This serves the same purpose as the \emph{APPLY MUTATION} algorithm in \cite{ButzWilson}.
%The method of mutation used is described in \S\ref{sec:mutation} here.

\subsection{The \emph{More General?} Predicate}
\label{sec:more-general?}
This is derived from the \emph{IS MORE GENERAL} function in \cite{ButzWilson}.

\begin{description}
\item [The \emph{more general?} predicate for a TSC predicate.]
This returns true only if the predicate $p$ matches predicate $q$ and if it is more general than it as well.
Predicate $p$ is more general than predicate $q$ if and only if:
\[p \textrm{ matches } q \land\]
\[ \left( l_p < l_q \lor u_q < u_p \lor
      \left( path_q \textrm{ lies completely along } path_p \land path_p \neq path_q\right)
   \right)
.\]

\item [The \emph{more general?} predicate for classifiers.]
This is based upon the algorithm called \emph{IS MORE GENERAL} in \cite{ButzWilson}, but it has been generalized in order to suit our needs here.
In traditional learning classifiers, it is only necessary to count the occurrences of the covering symbol, $\#$, in order to determine which of two classifiers is more general: the one with the greater number of occurrences of it.
For us it is slightly more involved due to the more complex nature of the conditions used in the construction of the classifiers.
A classifier $r^1$ is more general than another classifier $r^2$ if $r^1$ and $r^2$ match,
as decided by the \emph{match?} predicate described in \S\ref{sec:match?},
and at least one of the elements of the classifier is more general in $r^1$ than in $r^2$.

\end{description}
