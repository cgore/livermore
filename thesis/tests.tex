\section{Experimental Results}
\vspace*{-\baselineskip}
\subsection{The Nature of a Realistic Time Series}
The primary difficulty experienced in testing was an unknown aspect of time series themselves.
Originally the test problem was a very simple one-dimensional sine wave, with only a simple slope function for an operator, and with the classification task of deciding if the next point will be up or down from the current point.
This appears as if it were a trivial problem, and indeed a high degree of accuracy can be achieved with only two very simple rules:
if the previous point is below the current one then the next point will be above;
otherwise the next point will be below the current point.

This approach will not work in general.
There are several distinct types of time series, such as: up-trending, down-trending, steady, periodic, up-step, down-step, hills, and valleys.
Real-world time series are comprised of several of the characteristics from each type, and any system that would be capable of operating on a real-world time series would need to be able to handle all of the different types simultaneously.
The problem is that a simple slope operator is only capable of learning time series that are primarily linear, and a periodic time series such as the sine wave requires entirely different operators.

\subsection{The Simplistic Increasing/Decreasing Tests}
The original test time series was a sine wave, which is a perfect example of a periodic function, but the simple slope operator is only capable of learning linear time series data.
The new tests were designed with this in mind, and is actually a closer match to the appearance of real market data.

The first new test was simply a randomly chosen slope for a line, either upward or downward;
the classification question is still whether or not the next point will be above or below the current one; this was very quickly optimally learned by the system.

\enlargethispage{2\baselineskip}
In the second simple test, the series is randomly selected to be either upward or downward for a random number of time steps, with a randomly chosen slope, over and over again with completely different random elements each time.
This was also very quickly optimally learned by the system.

The third simple test added random noise to the second test;
TSC would typically optimally learn this problem within 1,000 to 2,000 time steps.

The fourth simple test randomly switched the direction of the time step with a certain probability.
This, as well, was optimally learned within 1,000 to 2,000 time steps.
This test would superficially resemble a traded entity, so it is of particular interest.
What is shown in Figures~4.1 and 4.2 is a typical run under this test, with a probability of exploration of 0.35 and a probability of random misdirection of 0.1;
% XXX: This is doing 4.2 for both figures for some reason.
%What is shown in Figures~\ref{fig:inde4plot} and \ref{fig:inde4perf} is a typical run under this test, with a probability of exploration of 0.35 and a probability of random misdirection of 0.1;
this would imply a best-case eventual accuracy of:
\[1 - \frac{0.35}{2} -0.1 = 0.725\]
or 72.5\%, which eventually appears.

\begin{figure}
\input{inde-values}
\label{fig:inde4plot}
\caption{Increasing/decreasing method 4 sample plot.}
\end{figure}

\begin{figure}
\input{inde-hist}
\label{fig:inde4perf}
\caption{Increasing/decreasing method 4 sample performance.}
\end{figure}

\subsection{The Stock Market}
\newcommand{\DJI}{\textasciicircum DJI}
We experimentally determined many of the parameters that are best for use on the stock market.
We used actual historical data of the Dow Jones Industrial Average (\DJI), with daily trading data starting on August 20, 1990, with data ending on August 18, 2006.
The data was gathered from Yahoo! Finance.
The first 100 data points of the time series were skipped, allowing for historical data that far back even in the very first day of simulated data, causing an actual start of analysis of January 11, 1991.
In each of these experiments, a statistical sample of at least 30 runs was gathered, each run going on for 1,500 simulated trading days (2,167 actual days, 5.93 years), for an end of December 16, 1996.
At each trading day the stock was given the option to either put all of its resources into the \DJI\ or into a bank account yielding roughly 4\% per annum.
The system initially had \$1,000,000.00.

In these trials we report:
\begin{enumerate}
\item the trial number,
\item the number of correct actions,
\item the percentage of correct actions,
\item the final financial return,
\item the ratio of the final financial return to that of the buy-and-hold strategy,
\item and the percentage returned per annum.
\end{enumerate}
We will use the buy-and-hold (B\&H) strategy as our primary performance benchmark.
In this strategy, the stock is purchased outright, and then the money is just left in the stock for the entire duration of the experiment.

\newenvironment{cgoreErt}[2]
{\begin{center}
   \begin{longtable}{|c|lrrlr|}
      \caption{#1}\label{#2}\remline\\
      \hline
      --- & \textbf{correct} & \textbf{\% correct} & \textbf{returns} & \textbf{B\&H ratio} & \textbf{\%pa}\\
      \hline
      B\&H & 806 & 53.733\% & \$2,745,309.50 & 1.0 & 18.54\%pa\\
      \hline
   \endfirsthead}
{\\ \hline\end{longtable}\end{center}}

Our initial parameters are listed in Table~\ref{tab:initial-parameters}, and were chosen by general trial and error throughout the software development process.

\begin{table}
\caption{Initial parameters for the TSC.}
\label{tab:initial-parameters}
\begin{tabular}{|r|l|}
   \hline
   \textbf{parameter} & \textbf{value} \\
   \hline
   max environment condition length & 10 \\
   valid operations & simple slope \\
   valid fields & closing price, opening price, and trading volume \\
   max total numerosity, $N$ & 400 \\
   learning rate, $\beta$ & 0.2 \\
   discount factor, $\gamma$ & 0.71 \\
   GA threshold, $\theta_{GA}$ & 25 \\
   equal error threshold, $\epsilon_0$ & 20.0 \\
   multiplier parameter, $\alpha$ & 0.1 \\
   crossover probability, $\chi$ & 0.8 \\
   mutation probability, $\mu$ & 0.04 \\
   exploration probability, $P_{explr}$ & 0.2 \\
   fitness fraction threshold, $\delta$ & 0.1 \\
   covering probability, $P_\#$ & 0.33 \\
   initial prediction, $p_I$ & 10.0 \\
   initial prediction error, $\epsilon_I$ & 0.0 \\
   initial fitness, $F_I$ & 0.01\\
   \hline
\end{tabular}
\end{table}

\input{tests-reward}

\input{tests-ga-threshold}

\input{tests-crossover-probability}

\input{tests-mutation-probability}

\input{tests-exploration-probability}

%\subsubsection{Maximum Environment Condition Lengths}
%Using all of the parameters we have discovered so far, we look now at how different maximum environment condition lengths, which we describe in \S\ref{sec:maximum-environment-condition-length}, can affect the outcome.
%We tested 1, 2, 5, 10, and 20.

%\subsubsection{Maximum Temporal Mutations}
%After all of this, still accumulating good parameters and using them for this test as well, we investigated the maximum temporal mutation, which we describe earlier in \S\ref{sec:maximum-temporal-mutation}.
%We looked at this value at 1, 2, 5, 8, and 10.

%\subsubsection{Maximum Position Mutations}
%Finally, with all of the previous parameters decided, we investigated the maximum position mutation, which we describe in \S\ref{sec:maximum-position-mutation}.
%We looked at 1, 2, 5, 8, and 10.
